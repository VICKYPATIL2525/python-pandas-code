{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {},
   "source": [
    "# Advanced Pandas Techniques for Data Analysis\n",
    "## Building on Basic Data Cleaning\n",
    "\n",
    "This notebook covers:\n",
    "1. Advanced data exploration and visualization\n",
    "2. Feature engineering techniques\n",
    "3. Categorical encoding\n",
    "4. Data aggregation with groupby\n",
    "5. Advanced filtering and selection\n",
    "6. Handling outliers\n",
    "7. Creating derived features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set display options for better readability\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.precision', 2)\n",
    "\n",
    "# Set visualization style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load_data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Titanic dataset\n",
    "data_path = 'C:\\\\Users\\\\vicky\\\\OneDrive\\\\Desktop\\\\Profound\\\\tested.csv'\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "# Display basic information\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"\\nColumns: {df.columns.tolist()}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exploration_header",
   "metadata": {},
   "source": [
    "## 1. Advanced Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "value_counts",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze categorical variables using value_counts()\n",
    "# This shows the distribution of values in each categorical column\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"PASSENGER CLASS DISTRIBUTION\")\n",
    "print(\"=\" * 50)\n",
    "print(df['Pclass'].value_counts().sort_index())\n",
    "print(f\"\\nPercentage distribution:\")\n",
    "print(df['Pclass'].value_counts(normalize=True).sort_index() * 100)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"GENDER DISTRIBUTION\")\n",
    "print(\"=\" * 50)\n",
    "print(df['Sex'].value_counts())\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"EMBARKATION PORT DISTRIBUTION\")\n",
    "print(\"=\" * 50)\n",
    "print(df['Embarked'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "correlation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correlation between numerical features\n",
    "# Correlation ranges from -1 to 1:\n",
    "# - Close to 1: strong positive correlation\n",
    "# - Close to -1: strong negative correlation\n",
    "# - Close to 0: no correlation\n",
    "\n",
    "numerical_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "correlation_matrix = df[numerical_cols].corr()\n",
    "\n",
    "print(\"Correlation with Survived:\")\n",
    "print(correlation_matrix['Survived'].sort_values(ascending=False))\n",
    "\n",
    "# Visualize correlation matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, \n",
    "            square=True, linewidths=1)\n",
    "plt.title('Correlation Matrix of Numerical Features')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unique_values",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check unique values and cardinality of each column\n",
    "# Cardinality = number of unique values\n",
    "# High cardinality columns (like Name, Ticket) are usually not useful for ML\n",
    "\n",
    "print(\"Column Cardinality Analysis:\")\n",
    "print(\"=\" * 60)\n",
    "for col in df.columns:\n",
    "    unique_count = df[col].nunique()\n",
    "    null_count = df[col].isnull().sum()\n",
    "    print(f\"{col:15} | Unique: {unique_count:4} | Nulls: {null_count:3} | Type: {df[col].dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feature_engineering_header",
   "metadata": {},
   "source": [
    "## 2. Feature Engineering\n",
    "Creating new features from existing ones can improve model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extract_title",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract title from passenger names\n",
    "# Titles (Mr., Mrs., Miss., etc.) can be a useful feature\n",
    "\n",
    "def extract_title(name):\n",
    "    \"\"\"Extract title from name string\"\"\"\n",
    "    if pd.isna(name):\n",
    "        return 'Unknown'\n",
    "    # Split by comma and period to get the title\n",
    "    title = name.split(',')[1].split('.')[0].strip()\n",
    "    return title\n",
    "\n",
    "# Create new 'Title' column\n",
    "df['Title'] = df['Name'].apply(extract_title)\n",
    "\n",
    "print(\"Title Distribution:\")\n",
    "print(df['Title'].value_counts())\n",
    "\n",
    "# Group rare titles into 'Other' category\n",
    "title_counts = df['Title'].value_counts()\n",
    "rare_titles = title_counts[title_counts < 10].index\n",
    "df['Title'] = df['Title'].replace(rare_titles, 'Other')\n",
    "\n",
    "print(\"\\nAfter grouping rare titles:\")\n",
    "print(df['Title'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "family_size",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Family Size feature\n",
    "# Family Size = SibSp (siblings/spouses) + Parch (parents/children) + 1 (self)\n",
    "\n",
    "df['FamilySize'] = df['SibSp'] + df['Parch'] + 1\n",
    "\n",
    "# Create IsAlone feature (1 if traveling alone, 0 otherwise)\n",
    "df['IsAlone'] = (df['FamilySize'] == 1).astype(int)\n",
    "\n",
    "print(\"Family Size Distribution:\")\n",
    "print(df['FamilySize'].value_counts().sort_index())\n",
    "\n",
    "print(\"\\nTraveling Alone:\")\n",
    "print(df['IsAlone'].value_counts())\n",
    "print(f\"\\nPercentage traveling alone: {df['IsAlone'].mean() * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "age_bins",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Age Groups by binning continuous Age variable\n",
    "# This converts numerical age into categorical groups\n",
    "\n",
    "# First, fill missing ages with median\n",
    "df['Age'].fillna(df['Age'].median(), inplace=True)\n",
    "\n",
    "# Create age bins\n",
    "age_bins = [0, 12, 18, 35, 60, 100]\n",
    "age_labels = ['Child', 'Teen', 'Young Adult', 'Adult', 'Senior']\n",
    "df['AgeGroup'] = pd.cut(df['Age'], bins=age_bins, labels=age_labels)\n",
    "\n",
    "print(\"Age Group Distribution:\")\n",
    "print(df['AgeGroup'].value_counts().sort_index())\n",
    "\n",
    "# Visualize age distribution\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "df['Age'].hist(bins=30, edgecolor='black')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Age Distribution')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "df['AgeGroup'].value_counts().sort_index().plot(kind='bar', color='skyblue', edgecolor='black')\n",
    "plt.xlabel('Age Group')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Age Group Distribution')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fare_bins",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Fare Categories using quantiles\n",
    "# Quantiles divide data into equal-sized groups\n",
    "\n",
    "# Fill missing fare\n",
    "df['Fare'].fillna(df['Fare'].median(), inplace=True)\n",
    "\n",
    "# Create fare categories based on quartiles\n",
    "df['FareCategory'] = pd.qcut(df['Fare'], q=4, labels=['Low', 'Medium', 'High', 'Very High'])\n",
    "\n",
    "print(\"Fare Category Distribution:\")\n",
    "print(df['FareCategory'].value_counts().sort_index())\n",
    "\n",
    "print(\"\\nFare statistics by category:\")\n",
    "print(df.groupby('FareCategory')['Fare'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "groupby_header",
   "metadata": {},
   "source": [
    "## 3. Data Aggregation with GroupBy\n",
    "GroupBy allows us to analyze data by categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "groupby_survival",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze survival rates by different features\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"SURVIVAL RATE BY PASSENGER CLASS\")\n",
    "print(\"=\" * 60)\n",
    "survival_by_class = df.groupby('Pclass')['Survived'].agg([\n",
    "    ('Count', 'count'),\n",
    "    ('Survived', 'sum'),\n",
    "    ('Survival_Rate', 'mean')\n",
    "])\n",
    "survival_by_class['Survival_Rate'] = survival_by_class['Survival_Rate'] * 100\n",
    "print(survival_by_class)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"SURVIVAL RATE BY GENDER\")\n",
    "print(\"=\" * 60)\n",
    "survival_by_sex = df.groupby('Sex')['Survived'].agg([\n",
    "    ('Count', 'count'),\n",
    "    ('Survived', 'sum'),\n",
    "    ('Survival_Rate', 'mean')\n",
    "])\n",
    "survival_by_sex['Survival_Rate'] = survival_by_sex['Survival_Rate'] * 100\n",
    "print(survival_by_sex)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"SURVIVAL RATE BY AGE GROUP\")\n",
    "print(\"=\" * 60)\n",
    "survival_by_age = df.groupby('AgeGroup')['Survived'].agg([\n",
    "    ('Count', 'count'),\n",
    "    ('Survived', 'sum'),\n",
    "    ('Survival_Rate', 'mean')\n",
    "])\n",
    "survival_by_age['Survival_Rate'] = survival_by_age['Survival_Rate'] * 100\n",
    "print(survival_by_age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "multi_groupby",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-level grouping: Survival by Class AND Gender\n",
    "\n",
    "print(\"Survival Rate by Passenger Class and Gender:\")\n",
    "print(\"=\" * 60)\n",
    "multi_group = df.groupby(['Pclass', 'Sex'])['Survived'].agg([\n",
    "    ('Count', 'count'),\n",
    "    ('Survived', 'sum'),\n",
    "    ('Survival_Rate', lambda x: f\"{x.mean() * 100:.1f}%\")\n",
    "])\n",
    "print(multi_group)\n",
    "\n",
    "# Pivot table for better visualization\n",
    "pivot_survival = df.pivot_table(\n",
    "    values='Survived',\n",
    "    index='Pclass',\n",
    "    columns='Sex',\n",
    "    aggfunc='mean'\n",
    ") * 100\n",
    "\n",
    "print(\"\\nPivot Table - Survival Rate % by Class and Gender:\")\n",
    "print(pivot_survival)\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(10, 6))\n",
    "pivot_survival.plot(kind='bar', color=['lightcoral', 'skyblue'])\n",
    "plt.title('Survival Rate by Passenger Class and Gender')\n",
    "plt.xlabel('Passenger Class')\n",
    "plt.ylabel('Survival Rate (%)')\n",
    "plt.legend(title='Gender')\n",
    "plt.xticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aggregate_stats",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate multiple statistics at once using agg()\n",
    "\n",
    "print(\"Comprehensive Statistics by Passenger Class:\")\n",
    "print(\"=\" * 80)\n",
    "class_stats = df.groupby('Pclass').agg({\n",
    "    'Age': ['mean', 'median', 'std'],\n",
    "    'Fare': ['mean', 'median', 'max'],\n",
    "    'Survived': ['sum', 'mean', 'count'],\n",
    "    'FamilySize': 'mean'\n",
    "}).round(2)\n",
    "\n",
    "print(class_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "encoding_header",
   "metadata": {},
   "source": [
    "## 4. Categorical Encoding\n",
    "Convert categorical variables to numerical for machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "label_encoding",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 1: Label Encoding (ordinal encoding)\n",
    "# Assigns a unique integer to each category\n",
    "# Best for ordinal data (data with natural order)\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Create a copy for encoding experiments\n",
    "df_encoded = df.copy()\n",
    "\n",
    "# Encode Sex column\n",
    "le_sex = LabelEncoder()\n",
    "df_encoded['Sex_Encoded'] = le_sex.fit_transform(df_encoded['Sex'])\n",
    "\n",
    "print(\"Label Encoding for Sex:\")\n",
    "print(df_encoded[['Sex', 'Sex_Encoded']].drop_duplicates().sort_values('Sex_Encoded'))\n",
    "\n",
    "# Encode Embarked column\n",
    "df_encoded['Embarked'].fillna('S', inplace=True)  # Fill missing with most common\n",
    "le_embarked = LabelEncoder()\n",
    "df_encoded['Embarked_Encoded'] = le_embarked.fit_transform(df_encoded['Embarked'])\n",
    "\n",
    "print(\"\\nLabel Encoding for Embarked:\")\n",
    "print(df_encoded[['Embarked', 'Embarked_Encoded']].drop_duplicates().sort_values('Embarked_Encoded'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "one_hot_encoding",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 2: One-Hot Encoding (dummy variables)\n",
    "# Creates binary columns for each category\n",
    "# Best for nominal data (no natural order)\n",
    "\n",
    "# One-hot encode Embarked\n",
    "embarked_dummies = pd.get_dummies(df['Embarked'], prefix='Embarked', drop_first=True)\n",
    "print(\"One-Hot Encoding for Embarked:\")\n",
    "print(embarked_dummies.head())\n",
    "\n",
    "# One-hot encode Sex\n",
    "sex_dummies = pd.get_dummies(df['Sex'], prefix='Sex', drop_first=True)\n",
    "print(\"\\nOne-Hot Encoding for Sex:\")\n",
    "print(sex_dummies.head())\n",
    "\n",
    "# One-hot encode Pclass\n",
    "pclass_dummies = pd.get_dummies(df['Pclass'], prefix='Pclass', drop_first=False)\n",
    "print(\"\\nOne-Hot Encoding for Pclass:\")\n",
    "print(pclass_dummies.head())\n",
    "\n",
    "# Combine all encoded features\n",
    "df_with_dummies = pd.concat([\n",
    "    df[['PassengerId', 'Survived', 'Age', 'Fare', 'FamilySize', 'IsAlone']],\n",
    "    pclass_dummies,\n",
    "    sex_dummies,\n",
    "    embarked_dummies\n",
    "], axis=1)\n",
    "\n",
    "print(\"\\nDataFrame with One-Hot Encoded Features:\")\n",
    "print(df_with_dummies.head())\n",
    "print(f\"\\nShape: {df_with_dummies.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "filtering_header",
   "metadata": {},
   "source": [
    "## 5. Advanced Filtering and Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complex_filtering",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complex filtering with multiple conditions\n",
    "\n",
    "# Example 1: Young females in first class\n",
    "young_first_class_females = df[\n",
    "    (df['Sex'] == 'female') & \n",
    "    (df['Pclass'] == 1) & \n",
    "    (df['Age'] < 30)\n",
    "]\n",
    "print(f\"Young females in first class: {len(young_first_class_females)}\")\n",
    "print(f\"Survival rate: {young_first_class_females['Survived'].mean() * 100:.1f}%\")\n",
    "\n",
    "# Example 2: Large families (> 4 members) in third class\n",
    "large_families_3rd = df[\n",
    "    (df['Pclass'] == 3) & \n",
    "    (df['FamilySize'] > 4)\n",
    "]\n",
    "print(f\"\\nLarge families in third class: {len(large_families_3rd)}\")\n",
    "print(f\"Survival rate: {large_families_3rd['Survived'].mean() * 100:.1f}%\")\n",
    "\n",
    "# Example 3: Using isin() for multiple values\n",
    "expensive_tickets = df[df['Fare'] > df['Fare'].quantile(0.75)]\n",
    "print(f\"\\nPassengers with expensive tickets (top 25%): {len(expensive_tickets)}\")\n",
    "print(f\"Survival rate: {expensive_tickets['Survived'].mean() * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "query_method",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using query() method for cleaner filtering syntax\n",
    "\n",
    "# Find adult males who survived\n",
    "result = df.query(\"Sex == 'male' and Age >= 18 and Survived == 1\")\n",
    "print(f\"Adult males who survived: {len(result)}\")\n",
    "\n",
    "# Complex query with variables\n",
    "min_fare = 50\n",
    "max_age = 40\n",
    "result2 = df.query(\"Fare > @min_fare and Age < @max_age and Pclass in [1, 2]\")\n",
    "print(f\"\\nPassengers matching complex criteria: {len(result2)}\")\n",
    "print(result2[['Name', 'Age', 'Fare', 'Pclass', 'Survived']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outliers_header",
   "metadata": {},
   "source": [
    "## 6. Outlier Detection and Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outlier_detection",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect outliers using IQR (Interquartile Range) method\n",
    "# Outliers are values that fall below Q1 - 1.5*IQR or above Q3 + 1.5*IQR\n",
    "\n",
    "def detect_outliers_iqr(data, column):\n",
    "    \"\"\"Detect outliers using IQR method\"\"\"\n",
    "    Q1 = data[column].quantile(0.25)\n",
    "    Q3 = data[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    \n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    \n",
    "    outliers = data[(data[column] < lower_bound) | (data[column] > upper_bound)]\n",
    "    \n",
    "    return outliers, lower_bound, upper_bound\n",
    "\n",
    "# Detect outliers in Fare\n",
    "fare_outliers, lower, upper = detect_outliers_iqr(df, 'Fare')\n",
    "print(f\"Fare Outliers Detection:\")\n",
    "print(f\"Lower bound: ${lower:.2f}\")\n",
    "print(f\"Upper bound: ${upper:.2f}\")\n",
    "print(f\"Number of outliers: {len(fare_outliers)}\")\n",
    "print(f\"\\nTop 5 highest fares:\")\n",
    "print(df.nlargest(5, 'Fare')[['Name', 'Fare', 'Pclass', 'Survived']])\n",
    "\n",
    "# Visualize outliers\n",
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.boxplot(df['Fare'].dropna())\n",
    "plt.title('Fare Distribution - Box Plot')\n",
    "plt.ylabel('Fare ($)')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "df['Fare'].hist(bins=50, edgecolor='black')\n",
    "plt.axvline(upper, color='red', linestyle='--', label=f'Upper bound: ${upper:.2f}')\n",
    "plt.title('Fare Distribution - Histogram')\n",
    "plt.xlabel('Fare ($)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "handle_outliers",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Methods to handle outliers\n",
    "\n",
    "# Method 1: Cap outliers (Winsorization)\n",
    "df_capped = df.copy()\n",
    "upper_cap = df['Fare'].quantile(0.95)\n",
    "df_capped['Fare_Capped'] = df_capped['Fare'].clip(upper=upper_cap)\n",
    "\n",
    "print(\"Original Fare statistics:\")\n",
    "print(df['Fare'].describe())\n",
    "print(\"\\nCapped Fare statistics:\")\n",
    "print(df_capped['Fare_Capped'].describe())\n",
    "\n",
    "# Method 2: Log transformation (for skewed data)\n",
    "df_transformed = df.copy()\n",
    "df_transformed['Fare_Log'] = np.log1p(df_transformed['Fare'])  # log1p = log(1+x)\n",
    "\n",
    "# Visualize transformation\n",
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "df['Fare'].hist(bins=50, edgecolor='black')\n",
    "plt.title('Original Fare Distribution')\n",
    "plt.xlabel('Fare')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "df_transformed['Fare_Log'].hist(bins=50, edgecolor='black', color='green')\n",
    "plt.title('Log-Transformed Fare Distribution')\n",
    "plt.xlabel('Log(Fare + 1)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "final_summary",
   "metadata": {},
   "source": [
    "## 7. Final Dataset Preparation for Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ml_ready_dataset",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a clean, ML-ready dataset\n",
    "\n",
    "# Start with a fresh copy\n",
    "df_ml = df.copy()\n",
    "\n",
    "# Fill missing values\n",
    "df_ml['Age'].fillna(df_ml['Age'].median(), inplace=True)\n",
    "df_ml['Fare'].fillna(df_ml['Fare'].median(), inplace=True)\n",
    "df_ml['Embarked'].fillna('S', inplace=True)\n",
    "\n",
    "# Select features for modeling\n",
    "features_to_keep = ['Pclass', 'Sex', 'Age', 'Fare', 'FamilySize', 'IsAlone', 'Embarked', 'Title']\n",
    "df_ml = df_ml[features_to_keep + ['Survived']]\n",
    "\n",
    "# Encode categorical variables\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le_sex = LabelEncoder()\n",
    "le_embarked = LabelEncoder()\n",
    "le_title = LabelEncoder()\n",
    "\n",
    "df_ml['Sex'] = le_sex.fit_transform(df_ml['Sex'])\n",
    "df_ml['Embarked'] = le_embarked.fit_transform(df_ml['Embarked'])\n",
    "df_ml['Title'] = le_title.fit_transform(df_ml['Title'])\n",
    "\n",
    "print(\"ML-Ready Dataset:\")\n",
    "print(df_ml.head())\n",
    "print(f\"\\nShape: {df_ml.shape}\")\n",
    "print(f\"\\nData types:\")\n",
    "print(df_ml.dtypes)\n",
    "print(f\"\\nMissing values:\")\n",
    "print(df_ml.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "train_test_split",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into features and target\n",
    "X = df_ml.drop('Survived', axis=1)\n",
    "y = df_ml['Survived']\n",
    "\n",
    "print(\"Features (X):\")\n",
    "print(X.head())\n",
    "print(f\"\\nShape: {X.shape}\")\n",
    "\n",
    "print(\"\\nTarget (y):\")\n",
    "print(y.head())\n",
    "print(f\"Shape: {y.shape}\")\n",
    "\n",
    "# Feature scaling (optional but recommended for many ML algorithms)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_scaled_df = pd.DataFrame(X_scaled, columns=X.columns)\n",
    "\n",
    "print(\"\\nScaled Features:\")\n",
    "print(X_scaled_df.head())\n",
    "print(\"\\nFeature Statistics After Scaling (should have mean≈0, std≈1):\")\n",
    "print(X_scaled_df.describe().round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conclusion",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### What We Learned:\n",
    "\n",
    "1. **Advanced Exploration**\n",
    "   - Value counts and distribution analysis\n",
    "   - Correlation analysis\n",
    "   - Cardinality checking\n",
    "\n",
    "2. **Feature Engineering**\n",
    "   - Extracting titles from names\n",
    "   - Creating family size features\n",
    "   - Binning continuous variables\n",
    "   - Quantile-based categorization\n",
    "\n",
    "3. **GroupBy Operations**\n",
    "   - Single and multi-level grouping\n",
    "   - Custom aggregations\n",
    "   - Pivot tables\n",
    "\n",
    "4. **Categorical Encoding**\n",
    "   - Label encoding for ordinal data\n",
    "   - One-hot encoding for nominal data\n",
    "\n",
    "5. **Advanced Filtering**\n",
    "   - Complex boolean conditions\n",
    "   - Query method\n",
    "\n",
    "6. **Outlier Handling**\n",
    "   - IQR method detection\n",
    "   - Capping (Winsorization)\n",
    "   - Log transformation\n",
    "\n",
    "7. **ML Preparation**\n",
    "   - Feature selection\n",
    "   - Encoding\n",
    "   - Scaling\n",
    "\n",
    "### Next Steps:\n",
    "- Train machine learning models\n",
    "- Cross-validation\n",
    "- Hyperparameter tuning\n",
    "- Model evaluation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
