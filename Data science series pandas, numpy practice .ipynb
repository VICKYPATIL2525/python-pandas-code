{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b003b3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries for data manipulation and analysis\n",
    "import pandas as pd  # pandas: powerful data manipulation library\n",
    "import numpy as np   # numpy: numerical computing library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca49dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# DATA SCIENCE WORKFLOW - STEP BY STEP GUIDE\n",
    "# ========================================\n",
    "# 1. Import the dataset\n",
    "# 2. Understand the dataset (shape, columns, data types)\n",
    "# 3. Understand the nature of the dataset:\n",
    "#    - Is it for analysis or Machine Learning?\n",
    "#    - Check distribution (bell curve, right skewed, left skewed)\n",
    "# 4. Check for null values\n",
    "# 5. Identify the column with most null values\n",
    "# 6. Handle null values by:\n",
    "#    - Removing rows/columns (recommended if >50% missing)\n",
    "#    - Replacing with mean (for numerical data with normal distribution)\n",
    "#    - Replacing with median (for skewed numerical data)\n",
    "#    - Replacing with mode (for categorical data)\n",
    "# 7. Adjust the dataframe as needed:\n",
    "#    - Rename columns for clarity\n",
    "#    - Change data types\n",
    "#    - Format dates\n",
    "# 8. Split dataset into train/test sets if needed for ML\n",
    "# 9. Save the cleaned file with proper naming and documentation\n",
    "# ========================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd138aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the file path to the dataset\n",
    "# Note: Use double backslash (\\\\) in Windows paths to escape the backslash character\n",
    "# Or use raw string r'path' or forward slash (/) which works cross-platform\n",
    "data = 'C:\\\\Users\\\\vicky\\\\OneDrive\\\\Desktop\\\\Profound\\\\tested.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1863c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV dataset into a pandas DataFrame\n",
    "# DataFrame is a 2D labeled data structure with columns of potentially different types\n",
    "df1 = pd.read_csv(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1500b5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the last 5 rows of the dataset to understand the data structure\n",
    "# Use tail() to see the end of the dataset\n",
    "# Use head() to see the first 5 rows (default)\n",
    "df1.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52366fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display all column names in the DataFrame\n",
    "# This helps us understand what features/variables we have\n",
    "# Note: columns is an attribute, not a method (no parentheses needed)\n",
    "df1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef2d37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get comprehensive information about the DataFrame:\n",
    "# - Number of entries (rows)\n",
    "# - Column names and their data types\n",
    "# - Non-null count (helps identify missing values)\n",
    "# - Memory usage\n",
    "df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc09818",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for null (missing) values in each column\n",
    "# isnull() returns boolean DataFrame, sum() counts True values per column\n",
    "# Results show: Age (86 nulls), Fare (1 null), Cabin (327 nulls)\n",
    "df1.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2832985e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DECISION: Handle missing values\n",
    "# - Cabin column has 327 out of 418 missing (78% missing) - will DROP this column\n",
    "# - Age column has 86 missing (20% missing) - will FILL with mean age\n",
    "# - Fare has only 1 missing - will FILL with mean fare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2601aa7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the 'Cabin' column due to excessive missing values (78%)\n",
    "# Parameters:\n",
    "#   - 'Cabin': column name to drop\n",
    "#   - axis=1: specifies we're dropping a column (axis=0 would drop rows)\n",
    "#   - inplace=True: modifies the DataFrame directly without creating a copy\n",
    "# Note: Using axis=1 instead of deprecated positional argument\n",
    "df1.drop('Cabin', axis=1, inplace=True)\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bedd9ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the updated DataFrame to verify the Cabin column was removed\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99865295",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next step: Fill missing Age values\n",
    "# Strategy: Use the average (mean) age as it's a reasonable estimate\n",
    "# for missing age data in a passenger dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4fd70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the average age and round to nearest integer\n",
    "# mean() calculates average, round() removes decimal places\n",
    "avg_age = round(df1['Age'].mean())\n",
    "print(f\"Average age of passengers: {avg_age} years\")\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dfc0f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing Age values with the calculated average age\n",
    "# fillna() replaces all NaN (null) values in the Age column\n",
    "# inplace=True modifies the column directly\n",
    "df1['Age'].fillna(avg_age, inplace=True)\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18fb22a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify null values after cleaning Age column\n",
    "# Should now show: Age (0 nulls), Fare (1 null remaining)\n",
    "df1.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d10e52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate descriptive statistics for numerical columns\n",
    "# describe() shows: count, mean, std, min, 25%, 50%, 75%, max\n",
    "# Useful for understanding data distribution and detecting outliers\n",
    "df1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1809a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill the single missing Fare value with the mean fare\n",
    "# Using mean() directly in fillna() to calculate and fill in one step\n",
    "df1['Fare'].fillna(df1['Fare'].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a9a57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final verification: Check that all null values have been handled\n",
    "# All columns should now show 0 null values\n",
    "df1.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c481eb91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# PREPARE DATA FOR MACHINE LEARNING\n",
    "# ========================================\n",
    "# Split the dataset into:\n",
    "# - Features (X): All columns except the target variable\n",
    "# - Target (y): The 'Survived' column (what we want to predict)\n",
    "# Note: Convention is X for features, y for target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd07005b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the target variable 'Survived' \n",
    "# Using double brackets [['Survived']] to get DataFrame (not Series)\n",
    "y = df1[['Survived']]\n",
    "print(f\"Target variable type: {type(y)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ade322",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy of the full dataset for feature extraction\n",
    "X = df1.copy()\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43e4ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the target variable from the features DataFrame\n",
    "# Now X contains only the features, y contains only the target\n",
    "X.drop('Survived', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60bb19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the features DataFrame (X)\n",
    "# Should contain all columns except 'Survived'\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2303022",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify the target variable (y)\n",
    "# Should only contain the 'Survived' column\n",
    "print(f\"Target variable type: {type(y)}\")\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e3e9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify the features DataFrame (X)\n",
    "# Should contain 10 columns (all except 'Survived')\n",
    "print(f\"Features type: {type(X)}\")\n",
    "print(f\"Features shape: {X.shape}\")\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d7467e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary: Data is now ready for Machine Learning!\n",
    "# X (Features): 418 rows × 10 columns\n",
    "# y (Target): 418 rows × 1 column\n",
    "# No missing values\n",
    "# Next steps would be:\n",
    "# 1. Encode categorical variables (Sex, Embarked, etc.)\n",
    "# 2. Scale numerical features if needed\n",
    "# 3. Split into train/test sets\n",
    "# 4. Train a model\n",
    "\n",
    "print(f\"\\\\nDataset Summary:\")\n",
    "print(f\"Features (X) shape: {X.shape}\")\n",
    "print(f\"Target (y) shape: {y.shape}\")\n",
    "print(f\"\\\\nData cleaning complete! Ready for ML pipeline.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db83c381",
   "metadata": {},
   "source": [
    "# Data Cleaning Complete! ✓\n",
    "\n",
    "**What we accomplished:**\n",
    "1. ✓ Loaded Titanic dataset (418 passengers)\n",
    "2. ✓ Explored data structure and identified issues\n",
    "3. ✓ Handled missing values:\n",
    "   - Dropped Cabin column (78% missing)\n",
    "   - Filled Age with mean (30 years)\n",
    "   - Filled Fare with mean\n",
    "4. ✓ Split data into Features (X) and Target (y)\n",
    "5. ✓ Dataset ready for machine learning!\n",
    "\n",
    "**Next steps for ML:**\n",
    "- Encode categorical variables\n",
    "- Feature engineering\n",
    "- Train/test split\n",
    "- Model training"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
